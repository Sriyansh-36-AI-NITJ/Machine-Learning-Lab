Dataset Link: https://www.kaggle.com/competitions/titanic/data?select=train.csv

1. Decision Tree:-
   This project implements a baseline Decision Tree classifier on the Titanic dataset to predict passenger survival. Exploratory Data Analysis (EDA) was performed to understand dataset shape, missing values, target distribution, and relationships between survival and key features like gender and age. Missing values were handled using median and mode imputation, and categorical variables were encoded using one-hot encoding. The dataset was split into training and validation sets to evaluate generalization performance. A Decision Tree model was chosen as a simple, interpretable baseline for classification tasks. Model performance was evaluated using Accuracy, which is appropriate for balanced binary classification problems.
2. SVM:-
   This project addresses a binary classification problem using the Titanic dataset to predict passenger survival. Basic exploratory data analysis was performed to understand the dataset structure, missing values, and target distribution. A Linear Support Vector Machine (SVM) was chosen due to its effectiveness in high-dimensional spaces and strong performance for binary classification tasks. Feature scaling was applied using a pipeline to prevent data leakage. The regularization parameter C was tuned using GridSearchCV with 5-fold cross-validation. Model performance was evaluated using ROC-AUC, which provides a robust measure of classification quality, especially in the presence of class imbalance.
   
3. Fairness Slice:-
   The model shows differing F1-scores for male and female passengers, indicating gender-based performance disparity. This occurs because gender is highly correlated with survival in the historical data, causing the model to favor female survival predictions. Such bias reflects historical rescue policies rather than inherent survival capability. Evaluating subgroup metrics helps identify these disparities. To mitigate bias, techniques such as removing sensitive attributes, re-weighting samples, or group-wise threshold tuning may be applied. Fairness-aware evaluation is essential for ethical machine learning systems.
